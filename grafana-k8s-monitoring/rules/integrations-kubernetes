groups:
    - name: kubernetes-apps
      rules:
        - alert: KubePodCrashLooping
          expr: |
            max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job!=""}[5m]) >= 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: 'Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff").'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodcrashlooping
            summary: Pod is crash looping.
        - alert: KubePodNotReady
          expr: |
            sum by (namespace, pod, job, cluster) (
              max by(namespace, pod, job, cluster) (
                kube_pod_status_phase{job!="", phase=~"Pending|Unknown|Failed"}
              ) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (
                1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"})
              )
            ) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubepodnotready
            summary: Pod has been in a non-ready state for more than 15 minutes.
        - alert: KubeDeploymentGenerationMismatch
          expr: |
            kube_deployment_status_observed_generation{job!=""}
              !=
            kube_deployment_metadata_generation{job!=""}
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentgenerationmismatch
            summary: Deployment generation mismatch due to possible roll-back.
        - alert: KubeDeploymentReplicasMismatch
          expr: |
            (
              kube_deployment_spec_replicas{job!=""}
                >
              kube_deployment_status_replicas_available{job!=""}
            ) and (
              changes(kube_deployment_status_replicas_updated{job!=""}[10m])
                ==
              0
            )
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentreplicasmismatch
            summary: Deployment has not matched the expected number of replicas.
        - alert: KubeDeploymentRolloutStuck
          expr: |
            kube_deployment_status_condition{condition="Progressing", status="false",job!=""}
            != 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Rollout of deployment {{ $labels.namespace }}/{{ $labels.deployment }} is not progressing for longer than 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedeploymentrolloutstuck
            summary: Deployment rollout is not progressing.
        - alert: KubeStatefulSetReplicasMismatch
          expr: |
            (
              kube_statefulset_status_replicas_ready{job!=""}
                !=
              kube_statefulset_status_replicas{job!=""}
            ) and (
              changes(kube_statefulset_status_replicas_updated{job!=""}[10m])
                ==
              0
            )
          for: 15m
          labels:
            severity: warning
          annotations:
            description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetreplicasmismatch
            summary: StatefulSet has not matched the expected number of replicas.
        - alert: KubeStatefulSetGenerationMismatch
          expr: |
            kube_statefulset_status_observed_generation{job!=""}
              !=
            kube_statefulset_metadata_generation{job!=""}
          for: 15m
          labels:
            severity: warning
          annotations:
            description: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetgenerationmismatch
            summary: StatefulSet generation mismatch due to possible roll-back.
        - alert: KubeStatefulSetUpdateNotRolledOut
          expr: |
            (
              max without (revision) (
                kube_statefulset_status_current_revision{job!=""}
                  unless
                kube_statefulset_status_update_revision{job!=""}
              )
                *
              (
                kube_statefulset_replicas{job!=""}
                  !=
                kube_statefulset_status_replicas_updated{job!=""}
              )
            )  and (
              changes(kube_statefulset_status_replicas_updated{job!=""}[5m])
                ==
              0
            )
          for: 15m
          labels:
            severity: warning
          annotations:
            description: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubestatefulsetupdatenotrolledout
            summary: StatefulSet update has not been rolled out.
        - alert: KubeDaemonSetRolloutStuck
          expr: |
            (
              (
                kube_daemonset_status_current_number_scheduled{job!=""}
                 !=
                kube_daemonset_status_desired_number_scheduled{job!=""}
              ) or (
                kube_daemonset_status_number_misscheduled{job!=""}
                 !=
                0
              ) or (
                kube_daemonset_status_updated_number_scheduled{job!=""}
                 !=
                kube_daemonset_status_desired_number_scheduled{job!=""}
              ) or (
                kube_daemonset_status_number_available{job!=""}
                 !=
                kube_daemonset_status_desired_number_scheduled{job!=""}
              )
            ) and (
              changes(kube_daemonset_status_updated_number_scheduled{job!=""}[5m])
                ==
              0
            )
          for: 15m
          labels:
            severity: warning
          annotations:
            description: DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetrolloutstuck
            summary: DaemonSet rollout is stuck.
        - alert: KubeContainerWaiting
          expr: |
            sum by (namespace, pod, container, job, cluster) (kube_pod_container_status_waiting_reason{job!=""}) > 0
          for: 1h
          labels:
            severity: warning
          annotations:
            description: pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecontainerwaiting
            summary: Pod container waiting longer than 1 hour.
        - alert: KubeDaemonSetNotScheduled
          expr: |
            kube_daemonset_status_desired_number_scheduled{job!=""}
              -
            kube_daemonset_status_current_number_scheduled{job!=""} > 0
          for: 10m
          labels:
            severity: warning
          annotations:
            description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetnotscheduled
            summary: DaemonSet pods are not scheduled.
        - alert: KubeDaemonSetMisScheduled
          expr: |
            kube_daemonset_status_number_misscheduled{job!=""} > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubedaemonsetmisscheduled
            summary: DaemonSet pods are misscheduled.
        - alert: KubeJobNotCompleted
          expr: |
            time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job!=""}
              and
            kube_job_status_active{job!=""} > 0) > 43200
          labels:
            severity: warning
          annotations:
            description: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than {{ "43200" | humanizeDuration }} to complete.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobnotcompleted
            summary: Job did not complete in time.
        - alert: KubeJobFailed
          expr: |
            kube_job_failed{job!=""}  > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubejobfailed
            summary: Job failed to complete.
        - alert: KubeHpaReplicasMismatch
          expr: |
            (kube_horizontalpodautoscaler_status_desired_replicas{job!=""}
              !=
            kube_horizontalpodautoscaler_status_current_replicas{job!=""})
              and
            (kube_horizontalpodautoscaler_status_current_replicas{job!=""}
              >
            kube_horizontalpodautoscaler_spec_min_replicas{job!=""})
              and
            (kube_horizontalpodautoscaler_status_current_replicas{job!=""}
              <
            kube_horizontalpodautoscaler_spec_max_replicas{job!=""})
              and
            changes(kube_horizontalpodautoscaler_status_current_replicas{job!=""}[15m]) == 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpareplicasmismatch
            summary: HPA has not matched desired number of replicas.
        - alert: KubeHpaMaxedOut
          expr: |
            kube_horizontalpodautoscaler_status_current_replicas{job!=""}
              ==
            kube_horizontalpodautoscaler_spec_max_replicas{job!=""}
          for: 15m
          labels:
            severity: warning
          annotations:
            description: HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubehpamaxedout
            summary: HPA is running at max replicas.
    - name: kubernetes-resources
      rules:
        - alert: KubeCPUOvercommit
          expr: |
            sum(namespace_cpu:kube_pod_container_resource_requests:sum{job!="",}) by (cluster) - (sum(kube_node_status_allocatable{job!="",resource="cpu"}) by (cluster) - max(kube_node_status_allocatable{job!="",resource="cpu"}) by (cluster)) > 0
            and
            (sum(kube_node_status_allocatable{job!="",resource="cpu"}) by (cluster) - max(kube_node_status_allocatable{job!="",resource="cpu"}) by (cluster)) > 0
          for: 10m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }} has overcommitted CPU resource requests for Pods by {{ $value }} CPU shares and cannot tolerate node failure.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuovercommit
            summary: Cluster has overcommitted CPU resource requests.
        - alert: KubeMemoryOvercommit
          expr: |
            sum(namespace_memory:kube_pod_container_resource_requests:sum{}) by (cluster) - (sum(kube_node_status_allocatable{resource="memory", job!=""}) by (cluster) - max(kube_node_status_allocatable{resource="memory", job!=""}) by (cluster)) > 0
            and
            (sum(kube_node_status_allocatable{resource="memory", job!=""}) by (cluster) - max(kube_node_status_allocatable{resource="memory", job!=""}) by (cluster)) > 0
          for: 10m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }} has overcommitted memory resource requests for Pods by {{ $value | humanize }} bytes and cannot tolerate node failure.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryovercommit
            summary: Cluster has overcommitted memory resource requests.
        - alert: KubeCPUQuotaOvercommit
          expr: |
            sum(min without(resource) (kube_resourcequota{job!="", type="hard", resource=~"(cpu|requests.cpu)"})) by (cluster)
              /
            sum(kube_node_status_allocatable{resource="cpu", job!=""}) by (cluster)
              > 1.5
          for: 5m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }}  has overcommitted CPU resource requests for Namespaces.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubecpuquotaovercommit
            summary: Cluster has overcommitted CPU resource requests.
        - alert: KubeMemoryQuotaOvercommit
          expr: |
            sum(min without(resource) (kube_resourcequota{job!="", type="hard", resource=~"(memory|requests.memory)"})) by (cluster)
              /
            sum(kube_node_status_allocatable{resource="memory", job!=""}) by (cluster)
              > 1.5
          for: 5m
          labels:
            severity: warning
          annotations:
            description: Cluster {{ $labels.cluster }}  has overcommitted memory resource requests for Namespaces.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubememoryquotaovercommit
            summary: Cluster has overcommitted memory resource requests.
        - alert: KubeQuotaAlmostFull
          expr: |
            kube_resourcequota{job!="", type="used"}
              / ignoring(instance, job, type)
            (kube_resourcequota{job!="", type="hard"} > 0)
              > 0.9 < 1
          for: 15m
          labels:
            severity: info
          annotations:
            description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaalmostfull
            summary: Namespace quota is going to be full.
        - alert: KubeQuotaFullyUsed
          expr: |
            kube_resourcequota{job!="", type="used"}
              / ignoring(instance, job, type)
            (kube_resourcequota{job!="", type="hard"} > 0)
              == 1
          for: 15m
          labels:
            severity: info
          annotations:
            description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotafullyused
            summary: Namespace quota is fully used.
        - alert: KubeQuotaExceeded
          expr: |
            kube_resourcequota{job!="", type="used"}
              / ignoring(instance, job, type)
            (kube_resourcequota{job!="", type="hard"} > 0)
              > 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage }} of its {{ $labels.resource }} quota.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubequotaexceeded
            summary: Namespace quota has exceeded the limits.
        - alert: CPUThrottlingHigh
          expr: |
            sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (cluster, container, pod, namespace)
              /
            sum(increase(container_cpu_cfs_periods_total{}[5m])) by (cluster, container, pod, namespace)
              > ( 25 / 100 )
          for: 15m
          labels:
            severity: info
          annotations:
            description: '{{ $value | humanizePercentage }} throttling of CPU in cluster {{ $labels.cluster }} namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }}.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-cputhrottlinghigh
            summary: Processes experience elevated CPU throttling.
    - name: kubernetes-system
      rules:
        - alert: KubeVersionMismatch
          expr: |
            count by (cluster) (count by (git_version, cluster) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"git_version","$1","git_version","(v[0-9]*.[0-9]*).*"))) > 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: There are {{ $value }} different semantic versions of Kubernetes components running.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeversionmismatch
            summary: Different semantic versions of Kubernetes components running.
        - alert: KubeClientErrors
          expr: |
            (sum(rate(rest_client_requests_total{job="kube-apiserver",code=~"5.."}[5m])) by (cluster, instance, job, namespace)
              /
            sum(rate(rest_client_requests_total{job="kube-apiserver"}[5m])) by (cluster, instance, job, namespace))
            > 0.01
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance }}' is experiencing {{ $value | humanizePercentage }} errors.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeclienterrors
            summary: Kubernetes API server client is experiencing errors.
    - name: kubernetes-system-kubelet
      rules:
        - alert: KubeNodeNotReady
          expr: |
            kube_node_status_condition{job!="",condition="Ready",status="true"} == 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: '{{ $labels.node }} has been unready for more than 15 minutes.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodenotready
            summary: Node is not ready.
        - alert: KubeNodeUnreachable
          expr: |
            (kube_node_spec_taint{job!="",key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{job!="",key=~"ToBeDeletedByClusterAutoscaler|cloud.google.com/impending-node-termination|aws-node-termination-handler/spot-itn"}) == 1
          for: 15m
          labels:
            severity: warning
          annotations:
            description: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodeunreachable
            summary: Node is unreachable.
        - alert: KubeletTooManyPods
          expr: |
            count by(cluster, node) (
              (kube_pod_status_phase{job!="",phase="Running"} == 1) * on(instance,pod,namespace,cluster) group_left(node) topk by(instance,pod,namespace,cluster) (1, kube_pod_info{job!=""})
            )
            /
            max by(cluster, node) (
              kube_node_status_capacity{job!="",resource="pods"} != 1
            ) > 0.95
          for: 15m
          labels:
            severity: info
          annotations:
            description: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage }} of its Pod capacity.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubelettoomanypods
            summary: Kubelet is running at capacity.
        - alert: KubeNodeReadinessFlapping
          expr: |
            sum(changes(kube_node_status_condition{job!="",status="true",condition="Ready"}[15m])) by (cluster, node) > 2
          for: 15m
          labels:
            severity: warning
          annotations:
            description: The readiness status of node {{ $labels.node }} has changed {{ $value }} times in the last 15 minutes.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubenodereadinessflapping
            summary: Node readiness status is flapping.
        - alert: KubeletPlegDurationHigh
          expr: |
            node_quantile:kubelet_pleg_relist_duration_seconds:histogram_quantile{quantile="0.99"} >= 10
          for: 5m
          labels:
            severity: warning
          annotations:
            description: The Kubelet Pod Lifecycle Event Generator has a 99th percentile duration of {{ $value }} seconds on node {{ $labels.node }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletplegdurationhigh
            summary: Kubelet Pod Lifecycle Event Generator is taking too long to relist.
        - alert: KubeletPodStartUpLatencyHigh
          expr: |
            histogram_quantile(0.99, sum(rate(kubelet_pod_worker_duration_seconds_bucket{job!=""}[5m])) by (cluster, instance, le)) * on(cluster, instance) group_left(node) kubelet_node_name{job!=""} > 60
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubelet Pod startup 99th percentile latency is {{ $value }} seconds on node {{ $labels.node }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletpodstartuplatencyhigh
            summary: Kubelet Pod startup latency is too high.
        - alert: KubeletClientCertificateExpiration
          expr: |
            kubelet_certificate_manager_client_ttl_seconds < 604800
          labels:
            severity: warning
          annotations:
            description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration
            summary: Kubelet client certificate is about to expire.
        - alert: KubeletClientCertificateExpiration
          expr: |
            kubelet_certificate_manager_client_ttl_seconds < 86400
          labels:
            severity: critical
          annotations:
            description: Client certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificateexpiration
            summary: Kubelet client certificate is about to expire.
        - alert: KubeletServerCertificateExpiration
          expr: |
            kubelet_certificate_manager_server_ttl_seconds < 604800
          labels:
            severity: warning
          annotations:
            description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration
            summary: Kubelet server certificate is about to expire.
        - alert: KubeletServerCertificateExpiration
          expr: |
            kubelet_certificate_manager_server_ttl_seconds < 86400
          labels:
            severity: critical
          annotations:
            description: Server certificate for Kubelet on node {{ $labels.node }} expires in {{ $value | humanizeDuration }}.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificateexpiration
            summary: Kubelet server certificate is about to expire.
        - alert: KubeletClientCertificateRenewalErrors
          expr: |
            increase(kubelet_certificate_manager_client_expiration_renew_errors[5m]) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubelet on node {{ $labels.node }} has failed to renew its client certificate ({{ $value | humanize }} errors in the last 5 minutes).
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletclientcertificaterenewalerrors
            summary: Kubelet has failed to renew its client certificate.
        - alert: KubeletServerCertificateRenewalErrors
          expr: |
            increase(kubelet_server_expiration_renew_errors[5m]) > 0
          for: 15m
          labels:
            severity: warning
          annotations:
            description: Kubelet on node {{ $labels.node }} has failed to renew its server certificate ({{ $value | humanize }} errors in the last 5 minutes).
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletservercertificaterenewalerrors
            summary: Kubelet has failed to renew its server certificate.
        - alert: KubeletDown
          expr: |
            absent(up{job!=""} == 1)
          for: 15m
          labels:
            severity: critical
          annotations:
            description: Kubelet in Cluster {{ $labels.cluster }}, has disappeared from Prometheus target discovery.
            runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md#alert-name-kubeletdown
            summary: Target disappeared from Prometheus target discovery.
    - name: k8s.rules.container_cpu_usage_seconds_total
      rules:
        - record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate
          expr: |
            sum by (cluster, namespace, pod, container) (
              irate(container_cpu_usage_seconds_total{job!="", image!=""}[5m])
            ) * on (cluster, namespace, pod) group_left(node) topk by (cluster, namespace, pod) (
              1, max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
            )
    - name: k8s.rules.container_memory_cache
      rules:
        - record: node_namespace_pod_container:container_memory_cache
          expr: |
            container_memory_cache{job!="", image!=""}
            * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
              max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
            )
    - name: k8s.rules.container_memory_swap
      rules:
        - record: node_namespace_pod_container:container_memory_swap
          expr: |
            container_memory_swap{job!="", image!=""}
            * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
              max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
            )
    - name: k8s.rules.container_memory_rss
      rules:
        - record: node_namespace_pod_container:container_memory_rss
          expr: |
            container_memory_rss{job!="", image!=""}
            * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
              max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
            )
    - name: k8s.rules.container_memory_working_set_bytes
      rules:
        - record: node_namespace_pod_container:container_memory_working_set_bytes
          expr: |
            container_memory_working_set_bytes{job!="", image!=""}
            * on (cluster, namespace, pod) group_left(node) topk by(cluster, namespace, pod) (1,
              max by(cluster, namespace, pod, node) (kube_pod_info{node!=""})
            )
    - name: k8s.rules.container_resource
      rules:
        - record: cluster:namespace:pod_memory:active:kube_pod_container_resource_requests
          expr: |
            kube_pod_container_resource_requests{resource="memory",job!=""}  * on (namespace, pod, cluster)
            group_left() max by (namespace, pod, cluster) (
              (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
            )
        - record: namespace_memory:kube_pod_container_resource_requests:sum
          expr: |
            sum by (namespace, cluster) (
                sum by (namespace, pod, cluster) (
                    max by (namespace, pod, container, cluster) (
                      kube_pod_container_resource_requests{resource="memory",job!=""}
                    ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                      kube_pod_status_phase{phase=~"Pending|Running"} == 1
                    )
                )
            )
        - record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_requests
          expr: |
            kube_pod_container_resource_requests{resource="cpu",job!=""}  * on (namespace, pod, cluster)
            group_left() max by (namespace, pod, cluster) (
              (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
            )
        - record: namespace_cpu:kube_pod_container_resource_requests:sum
          expr: |
            sum by (namespace, cluster) (
                sum by (namespace, pod, cluster) (
                    max by (namespace, pod, container, cluster) (
                      kube_pod_container_resource_requests{resource="cpu",job!=""}
                    ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                      kube_pod_status_phase{phase=~"Pending|Running"} == 1
                    )
                )
            )
        - record: cluster:namespace:pod_memory:active:kube_pod_container_resource_limits
          expr: |
            kube_pod_container_resource_limits{resource="memory",job!=""}  * on (namespace, pod, cluster)
            group_left() max by (namespace, pod, cluster) (
              (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
            )
        - record: namespace_memory:kube_pod_container_resource_limits:sum
          expr: |
            sum by (namespace, cluster) (
                sum by (namespace, pod, cluster) (
                    max by (namespace, pod, container, cluster) (
                      kube_pod_container_resource_limits{resource="memory",job!=""}
                    ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                      kube_pod_status_phase{phase=~"Pending|Running"} == 1
                    )
                )
            )
        - record: cluster:namespace:pod_cpu:active:kube_pod_container_resource_limits
          expr: |
            kube_pod_container_resource_limits{resource="cpu",job!=""}  * on (namespace, pod, cluster)
            group_left() max by (namespace, pod, cluster) (
             (kube_pod_status_phase{phase=~"Pending|Running"} == 1)
             )
        - record: namespace_cpu:kube_pod_container_resource_limits:sum
          expr: |
            sum by (namespace, cluster) (
                sum by (namespace, pod, cluster) (
                    max by (namespace, pod, container, cluster) (
                      kube_pod_container_resource_limits{resource="cpu",job!=""}
                    ) * on(namespace, pod, cluster) group_left() max by (namespace, pod, cluster) (
                      kube_pod_status_phase{phase=~"Pending|Running"} == 1
                    )
                )
            )
    - name: k8s.rules.pod_owner
      rules:
        - record: namespace_workload_pod:kube_pod_owner:relabel
          expr: |
            max by (cluster, namespace, workload, pod) (
              label_replace(
                label_replace(
                  kube_pod_owner{job!="", owner_kind="ReplicaSet"},
                  "replicaset", "$1", "owner_name", "(.*)"
                ) * on(replicaset, namespace) group_left(owner_name) topk by(replicaset, namespace) (
                  1, max by (replicaset, namespace, owner_name) (
                    kube_replicaset_owner{job!=""}
                  )
                ),
                "workload", "$1", "owner_name", "(.*)"
              )
            )
          labels:
            workload_type: deployment
        - record: namespace_workload_pod:kube_pod_owner:relabel
          expr: |
            max by (cluster, namespace, workload, pod) (
              label_replace(
                kube_pod_owner{job!="", owner_kind="DaemonSet"},
                "workload", "$1", "owner_name", "(.*)"
              )
            )
          labels:
            workload_type: daemonset
        - record: namespace_workload_pod:kube_pod_owner:relabel
          expr: |
            max by (cluster, namespace, workload, pod) (
              label_replace(
                kube_pod_owner{job!="", owner_kind="StatefulSet"},
                "workload", "$1", "owner_name", "(.*)"
              )
            )
          labels:
            workload_type: statefulset
        - record: namespace_workload_pod:kube_pod_owner:relabel
          expr: |
            max by (cluster, namespace, workload, pod) (
              label_replace(
                kube_pod_owner{job!="", owner_kind="Job"},
                "workload", "$1", "owner_name", "(.*)"
              )
            )
          labels:
            workload_type: job
    - name: k8s.windows-rules.container_memory_working_set_bytes
      rules:
        - record: container_memory_working_set_bytes
          expr: |
            label_replace(
              label_replace(
                windows_container_memory_usage_private_working_set_bytes{} * on(container_id) group_left(namespace, pod, container)
                topk by (container_id) (1, kube_pod_container_info{container_id != ""}),
                "id", "$1", "container_id", "(.*)"
              ), "image", "<not-supported-on-windows>", "", "")
    - name: k8s.windows-rules.container_memory_rss
      rules:
        - record: container_memory_rss
          expr: |
            label_replace(
              label_replace(
                windows_container_memory_usage_commit_bytes{} * on(container_id) group_left(namespace, pod, container)
                topk by (container_id) (1, kube_pod_container_info{container_id != ""}),
                "id", "$1", "container_id", "(.*)"
              ), "image", "<not-supported-on-windows>", "", "")
    - name: k8s.windows-rules.container_cpu_usage_seconds_total
      rules:
        - record: container_cpu_usage_seconds_total
          expr: |
            label_replace(
              label_replace(
                windows_container_cpu_usage_seconds_total{} * on(container_id) group_left(namespace, pod, container)
                topk by (container_id) (1, kube_pod_container_info{container_id != ""}),
                "id", "$1", "container_id", "(.*)"
              ), "image", "<not-supported-on-windows>", "", "")
